{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKHCJIjEMs31"
      },
      "source": [
        "# Проект для «Викишоп»"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpJRhiCIMs31"
      },
      "source": [
        "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
        "\n",
        "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
        "\n",
        "Постройте модель со значением метрики качества *F1* не меньше 0.75.\n",
        "\n",
        "**Инструкция по выполнению проекта**\n",
        "\n",
        "1. Загрузите и подготовьте данные.\n",
        "2. Обучите разные модели.\n",
        "3. Сделайте выводы.\n",
        "\n",
        "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
        "\n",
        "**Описание данных**\n",
        "\n",
        "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yc4vq3UMs31"
      },
      "outputs": [],
      "source": [
        "!pip install -q spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5eDJ5S6Ms32"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import spacy\n",
        "import re\n",
        "\n",
        "import joblib\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aKgntt5Ms32"
      },
      "outputs": [],
      "source": [
        "TEST_SIZE = 0.25\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpRtCv2sMs33"
      },
      "source": [
        "## Подготовка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQpX3K_jMs33",
        "outputId": "659a6c96-9c5d-44c2-bb4d-b7e94d1a6932"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                               text  toxic\n",
              "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
              "1           1  D'aww! He matches this background colour I'm s...      0\n",
              "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
              "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
              "4           4  You, sir, are my hero. Any chance you remember...      0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# загрузка данных\n",
        "df = pd.read_csv('/datasets/toxic_comments.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmBc3FoDMs33"
      },
      "source": [
        "Оставим только столбцы `text` и `toxic`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iV3KQom-Ms34"
      },
      "outputs": [],
      "source": [
        "df = df[['text', 'toxic']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHTVVKQRMs34"
      },
      "source": [
        "Определим функцию для вывода основной информации о датасете"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyEsXH4WMs34"
      },
      "outputs": [],
      "source": [
        "def data_info(data):\n",
        "    display(data.head())\n",
        "    data.info()\n",
        "    display(data.describe(include='all', datetime_is_numeric=True).T)\n",
        "    print()\n",
        "    print('Распределение данных по классам:')\n",
        "    print(df['toxic'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDE_fCZlMs34",
        "outputId": "4fa3171c-4222-4d81-94e2-f72c18c33805"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  toxic\n",
              "0  Explanation\\nWhy the edits made under my usern...      0\n",
              "1  D'aww! He matches this background colour I'm s...      0\n",
              "2  Hey man, I'm really not trying to edit war. It...      0\n",
              "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
              "4  You, sir, are my hero. Any chance you remember...      0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159292 entries, 0 to 159291\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   text    159292 non-null  object\n",
            " 1   toxic   159292 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 2.4+ MB\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>159292</td>\n",
              "      <td>159292</td>\n",
              "      <td>sorry \\n\\nFor stuffing the battery page - mt i...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>toxic</th>\n",
              "      <td>159292.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.101612</td>\n",
              "      <td>0.302139</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          count  unique                                                top  \\\n",
              "text     159292  159292  sorry \\n\\nFor stuffing the battery page - mt i...   \n",
              "toxic  159292.0     NaN                                                NaN   \n",
              "\n",
              "      freq      mean       std  min  25%  50%  75%  max  \n",
              "text     1       NaN       NaN  NaN  NaN  NaN  NaN  NaN  \n",
              "toxic  NaN  0.101612  0.302139  0.0  0.0  0.0  0.0  1.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Распределение данных по классам:\n",
            "0    143106\n",
            "1     16186\n",
            "Name: toxic, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "data_info(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4cEHW1BMs34"
      },
      "source": [
        "Пропусков и дубликатов в датасете не обнаружено, типы данных указаны корректно, а баланс классов смещен в сторону нетоксичных комментариев."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzp3m-D1Ms34"
      },
      "source": [
        "Разделим набор данных на обучающую и тестовую выборки и создадим списки текстов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMnoP4QHMs34"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop(['toxic'], axis=1),\n",
        "    df['toxic'],\n",
        "    test_size = TEST_SIZE,\n",
        "    random_state = RANDOM_STATE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYWFtFE0Ms35"
      },
      "outputs": [],
      "source": [
        "train_texts = X_train['text'].to_list()\n",
        "test_texts = X_test['text'].to_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS3ji4j2Ms35"
      },
      "source": [
        "Определим функции для очистки и лемматизации текста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXb0YRLpMs35"
      },
      "outputs": [],
      "source": [
        "# загрузка инструментов для работы с английским языком\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def lemm_text(texts):\n",
        "\n",
        "    # очистка текста от символов\n",
        "    clean_texts = [re.sub(r'[^a-zA-Z ]', ' ', text) for text in texts]\n",
        "\n",
        "    # разбиение списка текстов на порции\n",
        "    make_parts = lambda lst, sz: [lst[i:i+sz] for i in range(0, len(lst), sz)]\n",
        "    # разбиение на порции по 100 текстов\n",
        "    text_parts = make_parts(clean_texts, 100)\n",
        "\n",
        "    # слияние текстов с разделителем\n",
        "    res = []\n",
        "    for part in text_parts:\n",
        "        united_texts = ' '.join([text + '*' for text in part])\n",
        "\n",
        "        # лемматизация текстов после слияния\n",
        "        nlp_text_object = nlp(united_texts)\n",
        "        lemm_text_part = ' '.join([token.lemma_ for token in nlp_text_object])\n",
        "\n",
        "        # наполнение списка результатов\n",
        "        lemm_text_list = lemm_text_part.split('*')\n",
        "        for text in lemm_text_list[:-1]:\n",
        "            res.append(text)\n",
        "\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7bDUHjjMs35",
        "outputId": "d0e01f54-cfce-48fa-e672-3e470f28347b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 21min 34s, sys: 8.11 s, total: 21min 43s\n",
            "Wall time: 21min 44s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# создание корпуса лемматизированной тренировочной выборки\n",
        "with joblib.parallel_backend(\"threading\"):\n",
        "    X_train_corpus = lemm_text(train_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZd-eYsMMs35",
        "outputId": "1b3e1030-b5c8-49dc-dea5-a5e1d1e1b3f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "119469 119469\n",
            "==================================================\n",
            "The source was also not acceptable for reasons already stated. You also just rambled on about a load of nonsense.\n",
            "--------------------------------------------------\n",
            "the source be also not acceptable for reason already state   you also just ramble on about a load of nonsense \n",
            "==================================================\n",
            "\"\n",
            "I'm sorry, Tip; the deduction was obvious (and wrong). The article as written did not contain any links to reliable sources, depending instead on the subject's own website, amazon.com, and other notoriously unreliable sources. Remember also that Notability is not contagious; being the agent for a notable person does not make this guy notable. I'd suggest you rewrite this one in a sandbox, using more reliable sources; and if there are no such sources, consider what this says about the guy's notability. Your fellow cheesehead,   |  Talk \"\n",
            "--------------------------------------------------\n",
            "    I m sorry   Tip   the deduction be obvious   and wrong    the article as write do not contain any link to reliable source   depend instead on the subject s own website   amazon com   and other notoriously unreliable source   remember also that notability be not contagious   be the agent for a notable person do not make this guy notable   I d suggest you rewrite this one in a sandbox   use more reliable source   and if there be no such source   consider what this say about the guy s notability   your fellow cheesehead        Talk   \n"
          ]
        }
      ],
      "source": [
        "# проверка корректности лемматизации тренировочной выборки\n",
        "print(len(X_train_corpus), len(train_texts))\n",
        "print('=' * 50)\n",
        "print(train_texts[0])\n",
        "print('-' * 50)\n",
        "print(X_train_corpus[0])\n",
        "print('=' * 50)\n",
        "print(train_texts[-1])\n",
        "print('-' * 50)\n",
        "print(X_train_corpus[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlTNHfnWMs35",
        "outputId": "1616ddf1-e842-4803-d025-0d7474302bfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 7min 20s, sys: 4.76 s, total: 7min 25s\n",
            "Wall time: 7min 26s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# создание корпуса лемматизированной тестовой выборки\n",
        "with joblib.parallel_backend(\"threading\"):\n",
        "    X_test_corpus = lemm_text(test_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vn12A_FKMs35",
        "outputId": "423fb912-46bf-4eb1-c0cf-69269dee22d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "39823 39823\n",
            "==================================================\n",
            "Sometime back, I just happened to log on to www.izoom.in with a friend’s reference and I was amazed to see the concept Fresh Ideas Entertainment has come up with. So many deals… all under one roof. This website is very user friendly and easy to use and is fun to be on.\n",
            "You have Gossip, Games, Facts… Another exciting feature to add to it is Face of the Week… Every week, 4 new faces are selected and put up as izoom faces. It’s great to have been selected in four out of a group of millions. \n",
            "This new start up has already got many a deals in its kitty. Few of them being TheFortune Hotel, The Beach… are my personal favorites. izoom.in has a USP of mobile coupons. Coupons are available even when a user cannot access internet. You just need to SMS izoom support to 56767 and you get attended immediately.\n",
            "All I can say is izoom.in is a must visit website for everyone before they go out for shopping or dining or for outing.\n",
            "Cheers!!!\n",
            "--------------------------------------------------\n",
            "sometime back   I just happen to log on to www izoom in with a friend s reference and I be amazed to see the concept Fresh Ideas Entertainment have come up with   so many deal   all under one roof   this website be very user friendly and easy to use and be fun to be on   you have Gossip   Games   fact   another exciting feature to add to it be face of the Week   every week     new face be select and put up as izoom face   it s great to have be select in four out of a group of million    this new start up have already get many a deal in its kitty   few of they be TheFortune Hotel   the Beach   be my personal favorite   izoom in have a USP of mobile coupon   coupon be available even when a user can not access internet   you just need to sms izoom support to        and you get attend immediately   all I can say be izoom in be a must visit website for everyone before they go out for shopping or dining or for out   cheer    \n",
            "==================================================\n",
            "Thanks for the tip on the currency translation.  Think it's all done now.\n",
            "--------------------------------------------------\n",
            " thank for the tip on the currency translation    think it s all do now \n"
          ]
        }
      ],
      "source": [
        "# проверка корректности лемматизации тестовой выборки\n",
        "print(len(X_test_corpus), len(test_texts))\n",
        "print('=' * 50)\n",
        "print(test_texts[0])\n",
        "print('-' * 50)\n",
        "print(X_test_corpus[0])\n",
        "print('=' * 50)\n",
        "print(test_texts[3])\n",
        "print('-' * 50)\n",
        "print(X_test_corpus[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3i9wObOMs36"
      },
      "outputs": [],
      "source": [
        "# инициализация экземпляра класса векторизатора\n",
        "count = TfidfVectorizer(stop_words=set(stopwords.words('english')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHnTl3LAMs36",
        "outputId": "97e9bc1b-2c4b-47ab-bfe2-65eef32aa90b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 6.4 s, sys: 20 ms, total: 6.42 s\n",
            "Wall time: 6.45 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# преобразование корпуса слов тренировочной выборки\n",
        "X_train_tf_idf = count.fit_transform(X_train_corpus)\n",
        "# преобразование корпуса слов тестовой выборки\n",
        "X_test_tf_idf = count.transform(X_test_corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS8apgyhMs36"
      },
      "source": [
        "## Обучение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gAncfKeMs36"
      },
      "source": [
        "Инициализируем пайплайн для обучения моделей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyTekPGAMs36"
      },
      "outputs": [],
      "source": [
        "pipe_final = Pipeline([\n",
        "    ('models', LogisticRegression(random_state=RANDOM_STATE))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M10XoEjMs36"
      },
      "source": [
        "Зададим гиперпараметры"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "063NuO3UMs36"
      },
      "outputs": [],
      "source": [
        "param_grid = [\n",
        "    {\n",
        "        'models': [LogisticRegression(\n",
        "            random_state=RANDOM_STATE,\n",
        "            solver='liblinear',\n",
        "            penalty='l2'\n",
        "        )],\n",
        "        'models__C': [5, 10, 15],\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'models': [DecisionTreeClassifier(random_state=RANDOM_STATE)],\n",
        "        'models__max_features': range(6, 8),\n",
        "        'models__max_depth': range(8, 10)\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'models': [KNeighborsClassifier()],\n",
        "        'models__n_neighbors': [5, 25]\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rl4B0MqNMs36"
      },
      "outputs": [],
      "source": [
        "grid_search = GridSearchCV(\n",
        "    pipe_final,\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='f1',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHKNs5-JMs3-",
        "outputId": "d76bf7c1-751d-4f01-9062-826a5cb60a93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "Лучшая модель и её параметры:\n",
            "\n",
            " Pipeline(steps=[('models',\n",
            "                 LogisticRegression(C=15, random_state=42,\n",
            "                                    solver='liblinear'))])\n",
            "Метрика лучшей модели на тренировочной выборке: 0.766682041196146\n",
            "CPU times: user 13min 24s, sys: 6min 9s, total: 19min 34s\n",
            "Wall time: 19min 36s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# запуск подбора параметров\n",
        "with joblib.parallel_backend(\"threading\"):\n",
        "        grid_search.fit(X_train_tf_idf, y_train)\n",
        "\n",
        "print('Лучшая модель и её параметры:\\n\\n', grid_search.best_estimator_)\n",
        "print ('Метрика лучшей модели на тренировочной выборке:', grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dE8wu_jNMs3_",
        "outputId": "44405d35-d310-47a5-af87-512c5811c326"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_models</th>\n",
              "      <th>param_models__C</th>\n",
              "      <th>param_models__max_depth</th>\n",
              "      <th>param_models__max_features</th>\n",
              "      <th>param_models__n_neighbors</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.785714</td>\n",
              "      <td>0.686751</td>\n",
              "      <td>0.011516</td>\n",
              "      <td>0.000972</td>\n",
              "      <td>LogisticRegression(C=15, random_state=42, solv...</td>\n",
              "      <td>15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'models': LogisticRegression(C=15, random_sta...</td>\n",
              "      <td>0.765125</td>\n",
              "      <td>0.759722</td>\n",
              "      <td>0.778465</td>\n",
              "      <td>0.760439</td>\n",
              "      <td>0.769659</td>\n",
              "      <td>0.766682</td>\n",
              "      <td>0.006893</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14.929070</td>\n",
              "      <td>0.932095</td>\n",
              "      <td>0.010430</td>\n",
              "      <td>0.001102</td>\n",
              "      <td>LogisticRegression(C=15, random_state=42, solv...</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'models': LogisticRegression(C=15, random_sta...</td>\n",
              "      <td>0.764842</td>\n",
              "      <td>0.758653</td>\n",
              "      <td>0.778496</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.767104</td>\n",
              "      <td>0.765819</td>\n",
              "      <td>0.007050</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13.167403</td>\n",
              "      <td>0.761498</td>\n",
              "      <td>0.010342</td>\n",
              "      <td>0.001279</td>\n",
              "      <td>LogisticRegression(C=15, random_state=42, solv...</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'models': LogisticRegression(C=15, random_sta...</td>\n",
              "      <td>0.761120</td>\n",
              "      <td>0.752320</td>\n",
              "      <td>0.773723</td>\n",
              "      <td>0.756976</td>\n",
              "      <td>0.760610</td>\n",
              "      <td>0.760950</td>\n",
              "      <td>0.007121</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.030183</td>\n",
              "      <td>0.003997</td>\n",
              "      <td>93.850744</td>\n",
              "      <td>0.663450</td>\n",
              "      <td>KNeighborsClassifier()</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>{'models': KNeighborsClassifier(), 'models__n_...</td>\n",
              "      <td>0.249917</td>\n",
              "      <td>0.250171</td>\n",
              "      <td>0.256110</td>\n",
              "      <td>0.251768</td>\n",
              "      <td>0.243852</td>\n",
              "      <td>0.250364</td>\n",
              "      <td>0.003940</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.032839</td>\n",
              "      <td>0.000534</td>\n",
              "      <td>95.767897</td>\n",
              "      <td>1.770554</td>\n",
              "      <td>KNeighborsClassifier()</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25</td>\n",
              "      <td>{'models': KNeighborsClassifier(), 'models__n_...</td>\n",
              "      <td>0.117375</td>\n",
              "      <td>0.116647</td>\n",
              "      <td>0.112273</td>\n",
              "      <td>0.103623</td>\n",
              "      <td>0.094716</td>\n",
              "      <td>0.108927</td>\n",
              "      <td>0.008628</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.101449</td>\n",
              "      <td>0.004676</td>\n",
              "      <td>0.028232</td>\n",
              "      <td>0.001807</td>\n",
              "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'models': DecisionTreeClassifier(random_state...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001642</td>\n",
              "      <td>0.000821</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000493</td>\n",
              "      <td>0.000657</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.107041</td>\n",
              "      <td>0.007110</td>\n",
              "      <td>0.030295</td>\n",
              "      <td>0.002285</td>\n",
              "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'models': DecisionTreeClassifier(random_state...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001642</td>\n",
              "      <td>0.000821</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000493</td>\n",
              "      <td>0.000657</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.103524</td>\n",
              "      <td>0.003744</td>\n",
              "      <td>0.027805</td>\n",
              "      <td>0.001800</td>\n",
              "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'models': DecisionTreeClassifier(random_state...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000821</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000164</td>\n",
              "      <td>0.000329</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.110142</td>\n",
              "      <td>0.007792</td>\n",
              "      <td>0.028804</td>\n",
              "      <td>0.002238</td>\n",
              "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'models': DecisionTreeClassifier(random_state...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000821</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000164</td>\n",
              "      <td>0.000329</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "2      13.785714      0.686751         0.011516        0.000972   \n",
              "1      14.929070      0.932095         0.010430        0.001102   \n",
              "0      13.167403      0.761498         0.010342        0.001279   \n",
              "7       0.030183      0.003997        93.850744        0.663450   \n",
              "8       0.032839      0.000534        95.767897        1.770554   \n",
              "3       0.101449      0.004676         0.028232        0.001807   \n",
              "5       0.107041      0.007110         0.030295        0.002285   \n",
              "4       0.103524      0.003744         0.027805        0.001800   \n",
              "6       0.110142      0.007792         0.028804        0.002238   \n",
              "\n",
              "                                        param_models param_models__C  \\\n",
              "2  LogisticRegression(C=15, random_state=42, solv...              15   \n",
              "1  LogisticRegression(C=15, random_state=42, solv...              10   \n",
              "0  LogisticRegression(C=15, random_state=42, solv...               5   \n",
              "7                             KNeighborsClassifier()             NaN   \n",
              "8                             KNeighborsClassifier()             NaN   \n",
              "3            DecisionTreeClassifier(random_state=42)             NaN   \n",
              "5            DecisionTreeClassifier(random_state=42)             NaN   \n",
              "4            DecisionTreeClassifier(random_state=42)             NaN   \n",
              "6            DecisionTreeClassifier(random_state=42)             NaN   \n",
              "\n",
              "  param_models__max_depth param_models__max_features  \\\n",
              "2                     NaN                        NaN   \n",
              "1                     NaN                        NaN   \n",
              "0                     NaN                        NaN   \n",
              "7                     NaN                        NaN   \n",
              "8                     NaN                        NaN   \n",
              "3                       8                          6   \n",
              "5                       9                          6   \n",
              "4                       8                          7   \n",
              "6                       9                          7   \n",
              "\n",
              "  param_models__n_neighbors  \\\n",
              "2                       NaN   \n",
              "1                       NaN   \n",
              "0                       NaN   \n",
              "7                         5   \n",
              "8                        25   \n",
              "3                       NaN   \n",
              "5                       NaN   \n",
              "4                       NaN   \n",
              "6                       NaN   \n",
              "\n",
              "                                              params  split0_test_score  \\\n",
              "2  {'models': LogisticRegression(C=15, random_sta...           0.765125   \n",
              "1  {'models': LogisticRegression(C=15, random_sta...           0.764842   \n",
              "0  {'models': LogisticRegression(C=15, random_sta...           0.761120   \n",
              "7  {'models': KNeighborsClassifier(), 'models__n_...           0.249917   \n",
              "8  {'models': KNeighborsClassifier(), 'models__n_...           0.117375   \n",
              "3  {'models': DecisionTreeClassifier(random_state...           0.000000   \n",
              "5  {'models': DecisionTreeClassifier(random_state...           0.000000   \n",
              "4  {'models': DecisionTreeClassifier(random_state...           0.000000   \n",
              "6  {'models': DecisionTreeClassifier(random_state...           0.000000   \n",
              "\n",
              "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
              "2           0.759722           0.778465           0.760439           0.769659   \n",
              "1           0.758653           0.778496           0.760000           0.767104   \n",
              "0           0.752320           0.773723           0.756976           0.760610   \n",
              "7           0.250171           0.256110           0.251768           0.243852   \n",
              "8           0.116647           0.112273           0.103623           0.094716   \n",
              "3           0.001642           0.000821           0.000000           0.000000   \n",
              "5           0.001642           0.000821           0.000000           0.000000   \n",
              "4           0.000000           0.000821           0.000000           0.000000   \n",
              "6           0.000000           0.000821           0.000000           0.000000   \n",
              "\n",
              "   mean_test_score  std_test_score  rank_test_score  \n",
              "2         0.766682        0.006893                1  \n",
              "1         0.765819        0.007050                2  \n",
              "0         0.760950        0.007121                3  \n",
              "7         0.250364        0.003940                4  \n",
              "8         0.108927        0.008628                5  \n",
              "3         0.000493        0.000657                6  \n",
              "5         0.000493        0.000657                6  \n",
              "4         0.000164        0.000329                8  \n",
              "6         0.000164        0.000329                8  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = pd.DataFrame(grid_search.cv_results_)\n",
        "results.sort_values(by='rank_test_score', inplace=True)\n",
        "results.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-tyhawjMs3_"
      },
      "source": [
        "Выведем результаты лучших моделей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k8PACeyMs3_"
      },
      "source": [
        "Проверим качество лучшей модели на тестовой выборке"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OIAKmjIMs3_",
        "outputId": "cf60f95e-6b8c-4b80-de79-b7502b741ced"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1 на тестовой выборке: 0.7802182621909103\n"
          ]
        }
      ],
      "source": [
        "pred = grid_search.best_estimator_.predict(X_test_tf_idf)\n",
        "\n",
        "print(\"f1 на тестовой выборке:\", f1_score(y_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sgxJ1gaMs4A"
      },
      "source": [
        "## Выводы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKmZDW5kMs4A"
      },
      "source": [
        "В ходе выполнения проекта по классификации комментариев на негативные и позитивные были выполнены следующие шаги:  \n",
        "- сформирована тренировочная и тестовая выборки с использованием стратификации для обеспечения равномерного распределения комментариев каждого класса (т.к. токсичных коментариев в датасете оказалось значительно меньше),  \n",
        "- проведена лемматизация с помощью pymystem3, а также фильтрация специальных символов и стоп-слов,  \n",
        "- создан наборов признаков для обучения моделей с помощью TfIdfVectorizer,  \n",
        "- обучен ряд моделей: LogisticRegression, DecisionTreeClassifier и KNeighborsClassifier,  \n",
        "- оценена точность лучшей модели на тестовой выборке.  \n",
        "\n",
        "В результате, KNeighborsClassifier с параметрами n_neighbors=5 показала неплохие результаты, однако наилучшей моделью оказалась LogisticRegression с параметром регуляризации C=15, на тестовой выборке её качество составило 0.78 (f1_score)."
      ]
    }
  ],
  "metadata": {
    "ExecuteTimeLog": [
      {
        "duration": 2700,
        "start_time": "2025-05-28T04:14:28.139Z"
      },
      {
        "duration": 4649,
        "start_time": "2025-05-28T04:18:30.982Z"
      },
      {
        "duration": 3,
        "start_time": "2025-05-28T04:20:17.017Z"
      },
      {
        "duration": 926,
        "start_time": "2025-05-28T04:20:32.414Z"
      },
      {
        "duration": 11,
        "start_time": "2025-05-28T04:40:22.797Z"
      },
      {
        "duration": 4,
        "start_time": "2025-05-28T04:42:29.396Z"
      },
      {
        "duration": 274,
        "start_time": "2025-05-28T04:43:13.756Z"
      },
      {
        "duration": 3,
        "start_time": "2025-05-28T04:45:08.183Z"
      },
      {
        "duration": 245,
        "start_time": "2025-05-28T04:45:08.544Z"
      },
      {
        "duration": 34,
        "start_time": "2025-05-28T04:50:56.258Z"
      },
      {
        "duration": 11,
        "start_time": "2025-05-28T04:52:40.445Z"
      },
      {
        "duration": 621,
        "start_time": "2025-05-28T04:54:18.163Z"
      },
      {
        "duration": 1304141,
        "start_time": "2025-05-28T04:55:07.053Z"
      },
      {
        "duration": 5,
        "start_time": "2025-05-28T05:24:56.035Z"
      },
      {
        "duration": 446180,
        "start_time": "2025-05-28T05:25:23.791Z"
      },
      {
        "duration": 5,
        "start_time": "2025-05-28T05:40:05.601Z"
      },
      {
        "duration": 4,
        "start_time": "2025-05-28T05:40:42.865Z"
      },
      {
        "duration": 6457,
        "start_time": "2025-05-28T05:40:53.463Z"
      },
      {
        "duration": 3,
        "start_time": "2025-05-28T05:44:27.998Z"
      },
      {
        "duration": 4,
        "start_time": "2025-05-28T05:45:19.519Z"
      },
      {
        "duration": 3,
        "start_time": "2025-05-28T05:45:42.709Z"
      },
      {
        "duration": 1176020,
        "start_time": "2025-05-28T05:45:56.553Z"
      },
      {
        "duration": 33,
        "start_time": "2025-05-28T06:07:43.172Z"
      },
      {
        "duration": 20,
        "start_time": "2025-05-28T06:08:39.795Z"
      }
    ],
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Содержание",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "302.391px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}